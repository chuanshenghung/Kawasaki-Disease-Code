{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctgan import CTGAN\n",
    "from ctgan import load_demo\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble._bagging import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count_great(tmp_y_pred, tmp_y_pred2, y_test, y_pred):\n",
    "    num_count = []\n",
    "    tp = []\n",
    "    fn = []\n",
    "    tp_balance_num = 0\n",
    "    tp_imbalance_num = 0\n",
    "    tp_same_num = 0\n",
    "    fn_balance_num = 0\n",
    "    fn_imbalance_num = 0\n",
    "    fn_same_num = 0\n",
    "    for index, row in enumerate(y_test):\n",
    "        if y_test[index]==1:\n",
    "            if y_pred[index]==1:\n",
    "                if (tmp_y_pred[index] > tmp_y_pred2[index]) & ((tmp_y_pred[index] - tmp_y_pred2[index])>0.1):\n",
    "                    tp_imbalance_num += 1\n",
    "                elif (tmp_y_pred[index] < tmp_y_pred2[index]) & ((tmp_y_pred2[index] - tmp_y_pred[index] )>0.1):\n",
    "                    tp_balance_num += 1\n",
    "                else:\n",
    "                    tp_same_num += 1\n",
    "            else:\n",
    "                if (tmp_y_pred[index] < tmp_y_pred2[index]) & ((tmp_y_pred2[index] - tmp_y_pred[index])>0.1):\n",
    "                    fn_imbalance_num += 1\n",
    "                elif (tmp_y_pred[index] > tmp_y_pred2[index]) & ((tmp_y_pred[index] - tmp_y_pred2[index])>0.1):\n",
    "                    fn_balance_num += 1\n",
    "                else:\n",
    "                    fn_same_num += 1\n",
    "        else:\n",
    "            continue\n",
    "    tp.append(tp_imbalance_num)\n",
    "    tp.append(tp_balance_num)\n",
    "    tp.append(tp_same_num)\n",
    "    fn.append(fn_imbalance_num)\n",
    "    fn.append(fn_balance_num)\n",
    "    fn.append(fn_same_num)\n",
    "    num_count.append([tp, fn])\n",
    "    return num_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "Ka = pd.read_excel(\"川崎症病人(訓練用 第一階段).xlsx\")\n",
    "fever = pd.read_excel('發燒病人(訓練用 第一階段).xlsx')\n",
    "KD_val = pd.read_excel('KD_validation.xlsx')\n",
    "FC_val = pd.read_excel('FC_validation.xlsx')\n",
    "cmgh_20to23 = pd.read_excel('2020-23高長NewKD.xlsx')\n",
    "Ka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('川崎症病人(原): ', len(Ka))\n",
    "print('川崎症病人(<=5歲): ', len(Ka))\n",
    "#發燒患者已只含0~6(不含6)歲\n",
    "print('發燒病人: ', len(fever[fever['年齡(日)']<=1826]))\n",
    "print('發燒病人: ', len(fever))\n",
    "\n",
    "\n",
    "print('川崎症病人(驗證): ', len(KD_val))\n",
    "print('發燒病人(驗證): ', len(FC_val))\n",
    "print('川崎症病人(驗證): ', len(KD_val[KD_val['年齡(日)']<=1826]))\n",
    "print('發燒病人(驗證): ', len(FC_val[FC_val['年齡(日)']<=1826]))\n",
    "Ka = Ka[Ka['年齡(日)']<=1826]\n",
    "fever = fever[fever['年齡(日)']<=1826]\n",
    "KD_val = KD_val[KD_val['年齡(日)']<=1826]\n",
    "FC_val = FC_val[FC_val['年齡(日)']<=1826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmgh_20to23['確診日期'] = pd.to_datetime(cmgh_20to23['確診日期'])\n",
    "cmgh_20to23['BOD'] = pd.to_datetime(cmgh_20to23['BOD'])\n",
    "\n",
    "cmgh_20to23['年齡(日)'] = (cmgh_20to23['確診日期']-cmgh_20to23['BOD']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('川崎症病人(長庚驗證): ', len(cmgh_20to23[cmgh_20to23['年齡(日)']<=1826]))\n",
    "# cmgh_20to23 = cmgh_20to23[cmgh_20to23['年齡(日)']<=1826]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   _for_syn 為配合合成資料\n",
    "\n",
    "#   日期轉月份\n",
    "# Ka['輸入日期(月)'] = Ka['輸入日期'].dt.month\n",
    "# fever['輸入日期(月)'] = fever['輸入日期'].dt.month\n",
    "KD_val['輸入日期(月)'] = KD_val['輸入日期'].dt.month\n",
    "FC_val['輸入日期(月)'] = FC_val['輸入日期'].dt.month\n",
    "KD_val_for_syn = KD_val\n",
    "FC_val_for_syn = FC_val\n",
    "cmgh_20to23['輸入日期(月)'] = cmgh_20to23['確診日期'].dt.month\n",
    "cmgh_20to23_for_syn = cmgh_20to23\n",
    "\n",
    "#   one-hot\n",
    "# ka_month = pd.get_dummies(Ka['輸入日期(月)'], prefix='Month')\n",
    "# fever_month = pd.get_dummies(fever['輸入日期(月)'], prefix='Month')\n",
    "KD_month_val = pd.get_dummies(KD_val['輸入日期(月)'], prefix='Month')\n",
    "FC_month_val = pd.get_dummies(FC_val['輸入日期(月)'], prefix='Month')\n",
    "val_month = pd.get_dummies(cmgh_20to23['輸入日期(月)'], prefix='Month')\n",
    "\n",
    "#   檔案串接    raw + one-hot\n",
    "# Ka = pd.concat([Ka, ka_month], axis=1)\n",
    "# fever = pd.concat([fever, fever_month], axis=1)\n",
    "KD_val = pd.concat([KD_val, KD_month_val], axis=1)\n",
    "FC_val = pd.concat([FC_val, FC_month_val], axis=1)\n",
    "cmgh_20to23 = pd.concat([cmgh_20to23, val_month], axis=1)\n",
    "\n",
    "#   刪除多餘欄位\n",
    "# Ka = Ka.drop(columns=['輸入日期(月)', '輸入日期'])  #'輸入日期(月)', \n",
    "# fever = fever.drop(columns=['輸入日期(月)', '輸入日期'])    #'輸入日期(月)', \n",
    "KD_val = KD_val.drop(columns=['輸入日期(月)', '輸入日期'])\n",
    "FC_val = FC_val.drop(columns=['輸入日期(月)', '輸入日期'])\n",
    "KD_val_for_syn = KD_val_for_syn.drop(columns=['輸入日期'])\n",
    "FC_val_for_syn = FC_val_for_syn.drop(columns=['輸入日期'])\n",
    "cmgh_20to23 = cmgh_20to23.drop(columns=['輸入日期(月)', '確診日期'])\n",
    "cmgh_20to23_for_syn = cmgh_20to23_for_syn.drop(columns=['確診日期'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmgh_20to23.loc[cmgh_20to23['U/A WBC esterase']=='Positive', 'U/A WBC esterase'] = 1\n",
    "cmgh_20to23.loc[cmgh_20to23['U/A WBC esterase']=='negative', 'U/A WBC esterase'] = 0\n",
    "cmgh_20to23_for_syn.loc[cmgh_20to23_for_syn['U/A WBC esterase']=='Positive', 'U/A WBC esterase'] = 1\n",
    "cmgh_20to23_for_syn.loc[cmgh_20to23_for_syn['U/A WBC esterase']=='negative', 'U/A WBC esterase'] = 0\n",
    "\n",
    "#   刪除多餘欄位\n",
    "cmgh_20to23 = cmgh_20to23.drop(columns=[\"KD\",\"BOD\",\"Chart No\", \"KD1 Age\", \"MCV (fL)\",\"RDW-SD (fL)\"])\n",
    "cmgh_20to23_for_syn = cmgh_20to23_for_syn.drop(columns=[\"KD\",\"BOD\",\"Chart No\", \"KD1 Age\", \"MCV (fL)\",\"RDW-SD (fL)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ka = shuffle(Ka, random_state=30)\n",
    "fever = shuffle(fever, random_state=30)\n",
    "KD_val = shuffle(KD_val, random_state=30)\n",
    "FC_val = shuffle(FC_val, random_state=30)\n",
    "KD_val_for_syn = shuffle(KD_val_for_syn, random_state=30)\n",
    "FC_val_for_syn = shuffle(FC_val_for_syn, random_state=30)\n",
    "\n",
    "Ka['label'] = 1\n",
    "fever['label'] = 0\n",
    "KD_val['label'] = 1\n",
    "FC_val['label'] = 0\n",
    "KD_val_for_syn['label'] = 1\n",
    "FC_val_for_syn['label'] = 0\n",
    "cmgh_20to23['label'] = 1\n",
    "cmgh_20to23_for_syn['label'] = 1\n",
    "\n",
    "all_train_data = pd.concat([Ka, fever], ignore_index=True)\n",
    "validation_data = pd.concat([KD_val, FC_val], ignore_index=True)\n",
    "validation_data_for_syn = pd.concat([KD_val_for_syn, FC_val_for_syn], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ka.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_train_data.values[:,:-1]\n",
    "y = all_train_data.values[:,-1]\n",
    "x_val = validation_data.values[:,:-1]\n",
    "y_val = validation_data.values[:,-1]\n",
    "x_val_for_syn = validation_data_for_syn.values[:,:-1]\n",
    "y_val_for_syn = validation_data_for_syn.values[:,-1]\n",
    "cmgh_20to23_x_test = cmgh_20to23.values[:,:-1]\n",
    "cmgh_20to23_y_test = cmgh_20to23.values[:,-1]\n",
    "cmgh_20to23_x_test_for_syn = cmgh_20to23_for_syn.values[:,:-1]\n",
    "cmgh_20to23_y_test_for_syn = cmgh_20to23_for_syn.values[:,-1]\n",
    "\n",
    "tmp_x_train, tmp_x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, shuffle=True, stratify=y, random_state=30)\n",
    "FC_test_index = [index for (index, x) in enumerate(y_test) if x==0]     #取出測試資料中FC的index\n",
    "KD_test_index = [index for (index, x) in enumerate(y_test) if x==1]     #取出測試資料中KD的index\n",
    "cmgh_20to23_y_test = cmgh_20to23_y_test.astype(float)\n",
    "cmgh_20to23_y_test_for_syn = cmgh_20to23_y_test_for_syn.astype(float)\n",
    "y_train = y_train.astype('float')\n",
    "y_test = y_test.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = ['WBC','RBC','Hemoglobin','Hematocrit','MCH','MCHC','RDW','Platelets','Segment','Band','Lymphocyte','Monocyte','Eosinophil','Basophil','AST','ALT','CRP','UWBC','性別','年齡(日)','膿尿', '輸入日期']\n",
    "y_col = ['label']\n",
    "#   長庚 資料處理\n",
    "#   分為合成訓練  原始訓練\n",
    "df_tmp_x_train_for_syn = pd.DataFrame(tmp_x_train, columns=x_col)\n",
    "df_tmp_x_test_for_syn = pd.DataFrame(tmp_x_test, columns=x_col)\n",
    "df_tmp_x_train = pd.DataFrame(tmp_x_train, columns=x_col)\n",
    "df_tmp_x_test = pd.DataFrame(tmp_x_test, columns=x_col)\n",
    "df_tmp_y_train = pd.DataFrame(y_train, columns=y_col)\n",
    "\n",
    "df_tmp_x_train_for_syn['輸入日期(月)'] = df_tmp_x_train_for_syn['輸入日期'].dt.month\n",
    "df_tmp_x_test_for_syn['輸入日期(月)'] = df_tmp_x_test_for_syn['輸入日期'].dt.month\n",
    "df_tmp_x_train['輸入日期(月)'] = df_tmp_x_train['輸入日期'].dt.month\n",
    "df_tmp_x_test['輸入日期(月)'] = df_tmp_x_test['輸入日期'].dt.month\n",
    "\n",
    "df_tmp_x_train_month = pd.get_dummies(df_tmp_x_train['輸入日期(月)'], prefix='Month')\n",
    "df_tmp_x_test_month = pd.get_dummies(df_tmp_x_test['輸入日期(月)'], prefix='Month')\n",
    "\n",
    "df_tmp_x_train = pd.concat([df_tmp_x_train, df_tmp_x_train_month], axis=1)\n",
    "df_tmp_x_test = pd.concat([df_tmp_x_test, df_tmp_x_test_month], axis=1)\n",
    "\n",
    "df_tmp_x_train_for_syn = df_tmp_x_train_for_syn.drop(columns=['輸入日期'])\n",
    "df_tmp_x_test_for_syn = df_tmp_x_test_for_syn.drop(columns=['輸入日期'])\n",
    "df_tmp_x_train = df_tmp_x_train.drop(columns=['輸入日期(月)', '輸入日期'])  #'輸入日期(月)', \n",
    "df_tmp_x_test = df_tmp_x_test.drop(columns=['輸入日期(月)', '輸入日期'])    #'輸入日期(月)', \n",
    "\n",
    "df_tmp_train_for_syn = pd.concat([df_tmp_x_train_for_syn, df_tmp_y_train], axis=1)\n",
    "\n",
    "x_train = df_tmp_x_train.values\n",
    "x_test = df_tmp_x_test.values\n",
    "x_test_syn = df_tmp_x_test_for_syn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp_train_for_syn_FC = df_tmp_train_for_syn[df_tmp_train_for_syn['label']==0]\n",
    "df_tmp_train_for_syn_KD = df_tmp_train_for_syn[df_tmp_train_for_syn['label']==1]\n",
    "\n",
    "df_tmp_train_for_syn_KD = df_tmp_train_for_syn_KD.drop('label',axis=1)\n",
    "\n",
    "float_col = ['WBC','RBC','Hemoglobin','Hematocrit','MCH','MCHC','RDW','Platelets','Segment','Band','Lymphocyte','Monocyte','Eosinophil','Basophil','AST','ALT','CRP','UWBC']\n",
    "int_col = ['性別','年齡(日)','膿尿']\n",
    "\n",
    "for i in float_col:\n",
    "    df_tmp_train_for_syn_KD[i] = df_tmp_train_for_syn_KD[i].astype('float64')\n",
    "for i in int_col:\n",
    "    df_tmp_train_for_syn_KD[i] = df_tmp_train_for_syn_KD[i].astype('int64')\n",
    "\n",
    "# #   建立 metadata\n",
    "# metadata = SingleTableMetadata()\n",
    "# metadata.detect_from_dataframe(data=df_tmp_train_for_syn_KD)\n",
    "\n",
    "# #   建立模型\n",
    "# synthesizer = CTGANSynthesizer(metadata)\n",
    "# synthesizer.fit(df_tmp_train_for_syn_KD)\n",
    "\n",
    "#   儲存模型\n",
    "# synthesizer.save(\n",
    "#     filepath='Sdv_CTGAN_0706_2.pkl'\n",
    "# )\n",
    "\n",
    "#   執行儲存的模型\n",
    "# synthesizer = CTGANSynthesizer.load(\n",
    "#     filepath='Sdv_CTGAN_0706_1.pkl'\n",
    "# )\n",
    "# synthesizer.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   CTGAN 合成資料\n",
    "# synthesizer.reset_sampling()\n",
    "# print(len(df_tmp_train_for_syn_FC))\n",
    "# GAN_synthetic_data = synthesizer.sample(num_rows=len(df_tmp_train_for_syn_FC)-len(df_tmp_train_for_syn_KD))\n",
    "# print(len(GAN_synthetic_data))\n",
    "\n",
    "GAN_synthetic_data = pd.read_csv(\"GAN_synthetic_0817_3(1_4).csv\")\n",
    "\n",
    "GAN_synthetic_data['label'] = 1\n",
    "df_tmp_train_for_syn_KD['label'] = 1\n",
    "\n",
    "#   真實資料 + 合成資料\n",
    "all_train_data_GAN = pd.concat([df_tmp_train_for_syn_FC, df_tmp_train_for_syn_KD, GAN_synthetic_data], ignore_index=True)\n",
    "all_train_data_GAN = shuffle(all_train_data_GAN)\n",
    "\n",
    "x_train_GAN = all_train_data_GAN.values[:,:-1]\n",
    "y_train_GAN = all_train_data_GAN.values[:,-1]\n",
    "y_train_GAN = y_train_GAN.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   TVAE 合成資料\n",
    "TVAE_synthetic_data = pd.read_csv(\"TVAE_synthetic_0707_1.csv\")\n",
    "\n",
    "TVAE_synthetic_data['label'] = 1\n",
    "# df_tmp_train_for_syn_KD['label'] = 1\n",
    "\n",
    "#   真實資料 + 合成資料\n",
    "all_train_data_TVAE = pd.concat([df_tmp_train_for_syn_FC, df_tmp_train_for_syn_KD, TVAE_synthetic_data], ignore_index=True)\n",
    "all_train_data_TVAE = shuffle(all_train_data_TVAE)\n",
    "\n",
    "x_train_TVAE = all_train_data_TVAE.values[:,:-1]\n",
    "y_train_TVAE = all_train_data_TVAE.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   驗證集整合\n",
    "\n",
    "#   長庚raw + 高醫 + 長庚2020-22\n",
    "# test_index = KD_test_index[32:133] + FC_test_index\n",
    "# x_test = np.append(x_val, x_test[test_index], axis=0)\n",
    "# y_test = np.append(y_val, y_test[test_index], axis=0)\n",
    "# x_test = np.append(cmgh_20to23_x_test, x_test, axis=0)\n",
    "# y_test = np.append(cmgh_20to23_y_test, y_test, axis=0)\n",
    "\n",
    "# # x_test = np.append(x_val, x_test[sample(neg_index, 9000)], axis=0)\n",
    "# # y_test = np.append(y_val, y_test[sample(neg_index, 9000)], axis=0)\n",
    "\n",
    "#   使用純高醫資料驗證\n",
    "x_test = x_val\n",
    "y_test = y_val\n",
    "\n",
    "#   針對訓練集中結合合成資料 驗證集整合     y_test按照先前即可\n",
    "# test_index = KD_test_index[32:133] + FC_test_index\n",
    "# x_test_syn = np.append(x_val_for_syn , x_test_syn[test_index], axis=0)\n",
    "# x_test_syn = np.append(cmgh_20to23_x_test_for_syn, x_test_syn, axis=0)\n",
    "\n",
    "#   高醫\n",
    "x_test_syn = x_val_for_syn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm = SMOTE(random_state=42)\n",
    "# x_train_balance, y_train_balance = sm.fit_resample(x_train, y_train)\n",
    "# nm = NearMiss()\n",
    "# x_train_balance_nm, y_train_balance_nm = nm.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   XG + GAN\n",
    "GAN_xgb = XGBClassifier()\n",
    "GAN_xgb.fit(x_train_GAN, y_train_GAN)\n",
    "GAN_xg_y_pred_proba = GAN_xgb.predict_proba(x_test_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   XG + TVAE\n",
    "TVAE_xgb = XGBClassifier()\n",
    "TVAE_xgb.fit(x_train_TVAE, y_train_TVAE)\n",
    "TVAE_xg_y_pred_proba = TVAE_xgb.predict_proba(x_test_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()   #scale_pos_weight=35\n",
    "xgb.fit(x_train, y_train)\n",
    "xg_y_pred_proba = xgb.predict_proba(x_test)\n",
    "xg_thresh_list = []\n",
    "xg_accuracy_score_list = []\n",
    "xg_precision_score_list = []\n",
    "xg_recall_score_list = []\n",
    "xg_f1_score_list = []\n",
    "xg_record_f2_score = []\n",
    "xg_specificity_score_list = []\n",
    "xg_npv_score_list = []\n",
    "xg_confusion_matrix_list = []\n",
    "xg_y_pred_record = []\n",
    "for th in range(1,101):\n",
    "    th *= 0.01\n",
    "\n",
    "    y_pred = [0 if (x[0] >= th) else 1 for x in xg_y_pred_proba]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    npv = tn / (fn+tn)\n",
    "    xg_thresh_list.append(th)\n",
    "    xg_accuracy_score_list.append(accuracy_score(y_test, y_pred) * 100)\n",
    "    xg_precision_score_list.append(precision_score(y_test, y_pred) * 100)\n",
    "    xg_recall_score_list.append(recall_score(y_test, y_pred) * 100)\n",
    "    xg_f1_score_list.append(f1_score(y_test, y_pred) * 100)\n",
    "    xg_record_f2_score.append(fbeta_score(y_test, y_pred, beta=2) * 100)\n",
    "    xg_specificity_score_list.append(specificity * 100)\n",
    "    xg_npv_score_list.append(npv * 100)\n",
    "    xg_confusion_matrix_list.append([tn, fp, fn, tp])\n",
    "    xg_y_pred_record.append(y_pred)\n",
    "recall_standard_list = [80, 85, 90, 95]\n",
    "compare = []\n",
    "for recall_standard in recall_standard_list:\n",
    "    high_recall_f1score = []\n",
    "    high_recall_f2score = []\n",
    "    high_recall_accuracy = []\n",
    "    high_recall_recall = []\n",
    "    high_recall_precision = []\n",
    "    high_recall_specificity = []\n",
    "    high_recall_npv = []\n",
    "    high_recall_confusion_matrix = []\n",
    "    high_y_pred_record = []\n",
    "    for index, recall in enumerate(xg_recall_score_list):\n",
    "        if recall >= recall_standard:\n",
    "            high_recall_f1score.append(xg_f1_score_list[index])\n",
    "            high_recall_f2score.append(xg_record_f2_score[index])\n",
    "            high_recall_accuracy.append(xg_accuracy_score_list[index])\n",
    "            high_recall_precision.append(xg_precision_score_list[index])\n",
    "            high_recall_recall.append(xg_recall_score_list[index])\n",
    "            high_recall_specificity.append(xg_specificity_score_list[index])\n",
    "            high_recall_npv.append(xg_npv_score_list[index])\n",
    "            high_recall_confusion_matrix.append(xg_confusion_matrix_list[index])\n",
    "            high_y_pred_record.append(xg_y_pred_record[index])\n",
    "    high_recall_best_f1_score_index = np.argmax(high_recall_f1score)\n",
    "    print(\"當Recall高於\", recall_standard, \"% 時\")\n",
    "    print(\"且選取最高的F1-score時\")\n",
    "    print(\"Recall為為:\", high_recall_recall[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"Specificity為:\", high_recall_specificity[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"Precision為:\", high_recall_precision[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"NPV為:\", high_recall_npv[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"+LR:\", (high_recall_recall[high_recall_best_f1_score_index]/100)/(1-(high_recall_specificity[high_recall_best_f1_score_index]/100)))\n",
    "    print(\"-LR:\", (1-(high_recall_recall[high_recall_best_f1_score_index]/100))/(high_recall_specificity[high_recall_best_f1_score_index]/100))\n",
    "    print(\"F1 Score為:\", high_recall_f1score[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"F2 Score為:\", high_recall_f2score[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"Accuracy為:\", high_recall_accuracy[high_recall_best_f1_score_index], \"%\")\n",
    "    print(\"TN, FP, FN, TP\", high_recall_confusion_matrix[high_recall_best_f1_score_index])\n",
    "    # print('預測值', high_y_pred_record[high_recall_best_f1_score_index])\n",
    "    print(len(high_y_pred_record[high_recall_best_f1_score_index]))\n",
    "    print(\"============================================\")\n",
    "    compare.append(high_y_pred_record[high_recall_best_f1_score_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = [ \n",
    "    # ('gn', GaussianNB()),\n",
    "    # ('mn', MultinomialNB()),\n",
    "    ('ab', AdaBoostClassifier(n_estimators=59)),   \n",
    "    ('xgb', XGBClassifier(scale_pos_weight=34)), \n",
    "    ('cat', CatBoostClassifier()),\n",
    "    # ('rf', RandomForestClassifier()),   #n_estimators=200\n",
    "    # ('dt', DecisionTreeClassifier()),   #class_weight={1: 1000}\n",
    "    # ('svc', SVC(class_weight={1: 10}, probability=True)),\n",
    "    # ('knn', KNeighborsClassifier(n_neighbors=100)),   \n",
    "    # ('gb', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "\n",
    "record_recall = []\n",
    "record_specificity = []\n",
    "record_precision = []\n",
    "record_npv = []\n",
    "record_f1_score = []\n",
    "record_f2_score = []\n",
    "record_accuracy = []\n",
    "record_y_pred_pr = []\n",
    "sequences = [1, 11, 19, 40, 73, 139]\n",
    "# for i in sequences:\n",
    "for i in range(30, 31):\n",
    "    clf = StackingClassifier(estimators=est, final_estimator=LogisticRegression(class_weight={1:i}), cv=5)      #LogisticRegression(class_weight={1:i})\n",
    "    clf.fit(x_train, y_train)\n",
    "    tmp_y_pred = clf.predict_proba(x_test)\n",
    "    y_pred = [0 if (x[0] >= 0.5) else 1 for x in tmp_y_pred]\n",
    "    tmp_y_pred_pr = [x[1] for x in tmp_y_pred]\n",
    "    record_y_pred_pr.append(tmp_y_pred_pr)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    npv = tn / (tn+fn)\n",
    "    record_precision.append(precision_score(y_test, y_pred))\n",
    "    record_npv.append(npv)\n",
    "    record_recall.append(recall_score(y_test, y_pred))\n",
    "    record_specificity.append(specificity)\n",
    "    record_f1_score.append(f1_score(y_test, y_pred))\n",
    "    record_f2_score.append(fbeta_score(y_test, y_pred, beta=2))\n",
    "    record_accuracy.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est2 = [     #tmp best: ada, xgb, cat \n",
    "    ('ab', AdaBoostClassifier()), \n",
    "    ('xgb', XGBClassifier()),    \n",
    "    ('cat', CatBoostClassifier()),\n",
    "]\n",
    "\n",
    "# record_recall2 = []\n",
    "# record_specificity2 = []\n",
    "# record_precision2 = []\n",
    "# record_npv2 = []\n",
    "# record_f1_score2 = []\n",
    "# record_f2_score2 = []\n",
    "# record_accuracy2 = []\n",
    "# record_y_pred2_pr = []\n",
    "#配200 1900\n",
    "for i in range(5, 6):\n",
    "    clf2 = StackingClassifier(estimators=est2, final_estimator=LogisticRegression(class_weight={1:i}), cv=5, n_jobs=5)      #LogisticRegression(class_weight={1:i})\n",
    "    clf2.fit(x_train_GAN, y_train_GAN)\n",
    "    tmp_y_pred2 = clf2.predict_proba(x_test_syn)\n",
    "    # y_pred2 = [0 if (x[0] >= 0.5) else 1 for x in tmp_y_pred2]\n",
    "    # tmp_y_pred2_pr = [x[1] for x in tmp_y_pred2]\n",
    "    # record_y_pred2_pr.append(tmp_y_pred2_pr)\n",
    "    # tn, fp, fn, tp = confusion_matrix(y_test, y_pred2).ravel()\n",
    "    # specificity = tn / (tn+fp)\n",
    "    # npv = tn / (tn+fn)\n",
    "    # record_precision2.append(precision_score(y_test, y_pred2))\n",
    "    # record_npv2.append(npv)\n",
    "    # record_recall2.append(recall_score(y_test, y_pred2))\n",
    "    # record_specificity2.append(specificity)\n",
    "    # record_f1_score2.append(f1_score(y_test, y_pred2))\n",
    "    # record_f2_score2.append(fbeta_score(y_test, y_pred2, beta=2))\n",
    "    # record_accuracy2.append(accuracy_score(y_test, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_append_0 = np.append([tmp_y_pred[:,0]], [tmp_y_pred2[:,0]], axis=0)\n",
    "mean_y_pred_0 = np.mean(y_pred_append_0, axis=0)\n",
    "y_pred_append_1 = np.append([tmp_y_pred[:,1]], [tmp_y_pred2[:,1]], axis=0)\n",
    "mean_y_pred_1 = np.mean(y_pred_append_1, axis=0)\n",
    "y_pred_append = np.append([mean_y_pred_0], [mean_y_pred_1], axis=0)\n",
    "soft_y_pred = [0 if (x >= 0.5) else 1 for x in y_pred_append[0]]\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, soft_y_pred).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "npv = tn / (tn+fn)\n",
    "print('recall: ', recall_score(y_test, soft_y_pred))\n",
    "print('specificity: ', specificity)\n",
    "print('precision: ', precision_score(y_test, soft_y_pred))\n",
    "print('NPV: ', npv)\n",
    "print('f1_score: ', f1_score(y_test, soft_y_pred))\n",
    "print('f2_score: ', fbeta_score(y_test, soft_y_pred, beta=2))\n",
    "print('accuracy_score: ', accuracy_score(y_test, soft_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(1):\n",
    "    print('----------------------------------------------')\n",
    "    # print(sequences[i])\n",
    "    print(i+30)\n",
    "    print('recall: ', record_recall[i])\n",
    "    print('specificity: ', record_specificity[i])\n",
    "    print('precision: ', record_precision[i])\n",
    "    print('NPV: ', record_npv[i])\n",
    "    print('f1_score: ', record_f1_score[i])\n",
    "    print('f2_score: ', record_f2_score[i])\n",
    "    print('accuracy_score: ', record_accuracy[i])\n",
    "    print(\"+LR:\", (record_recall[i])/(1-(record_specificity[i])))\n",
    "    print(\"-LR:\", (1-(record_recall[i]))/(record_specificity[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(list(record_y_pred_pr[0]))[:10])\n",
    "# print(sorted(list(record_y_pred_pr[1]))[:10])\n",
    "# print(sorted(list(record_y_pred_pr[2]))[:10])\n",
    "# print(sorted(list(record_y_pred_pr[3]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pr curve\n",
    "for i in record_y_pred_pr:\n",
    "    xg_y_pred_pr = [x[1] for x in xg_y_pred_proba]\n",
    "    GAN_xg_y_pred_pr = [x[1] for x in GAN_xg_y_pred_proba]\n",
    "    TVAE_xg_y_pred_pr = [x[1] for x in TVAE_xg_y_pred_proba]\n",
    "    y_pred_append_pr = [x for x in y_pred_append[1]]\n",
    "    x = np.arange(0, 1, 0.001)\n",
    "    y = np.arange(1, 0, -0.001)\n",
    "    fig, ax = plt.subplots()\n",
    "    xg_precision, xg_recall, xg_thresholds = metrics.precision_recall_curve(y_test, xg_y_pred_pr, pos_label=1)\n",
    "    plt.plot(xg_recall, xg_precision, label = \"XG (val)\")       #, color='m'\n",
    "    # PrecisionRecallDisplay.from_predictions(y_test, xg_y_pred_pr, name=\"XG PR curve\", ax=ax)\n",
    "    GAN_xg_precision, GAN_xg_recall, GAN_xg_thresholds = metrics.precision_recall_curve(y_test, GAN_xg_y_pred_pr, pos_label=1)\n",
    "    plt.plot(GAN_xg_recall, GAN_xg_precision, label = \"CTGAN + XG (val)\")     #, color='b'\n",
    "    # PrecisionRecallDisplay.from_predictions(y_test, GAN_xg_y_pred_pr, name=\"CTGAN + XG PR curve\", ax=ax)\n",
    "    TVAE_xg_precision, TVAE_xg_recall, TVAE_xg_thresholds = metrics.precision_recall_curve(y_test, TVAE_xg_y_pred_pr, pos_label=1)\n",
    "    plt.plot(TVAE_xg_recall, TVAE_xg_precision, label = \"TVAE + XG (val)\")     #, color='b'\n",
    "    # PrecisionRecallDisplay.from_predictions(y_test, TVAE_xg_y_pred_pr, name=\"TVAE + XG PR curve\", ax=ax)\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_test, i, pos_label=1)\n",
    "    plt.plot(recall, precision, label = \"DC (val)\")    #, color='y'\n",
    "    # PrecisionRecallDisplay.from_predictions(y_test, i, name=\"ENS PR curve\", ax=ax)\n",
    "    CT_ENS_precision, CT_ENS_recall, CT_ENS_thresholds = metrics.precision_recall_curve(y_test, y_pred_append_pr, pos_label=1)\n",
    "    plt.plot(CT_ENS_recall, CT_ENS_precision, label = \"CTGAN-DC (val)\")    #, color='y'\n",
    "    # PrecisionRecallDisplay.from_predictions(y_test, y_pred_append_pr, name=\"ENS+ PR curve\", ax=ax)\n",
    "    # plt.plot(x, y, color='0', linestyle = \"-.\")\n",
    "\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.legend(loc=3)\n",
    "    plt.grid(True)\n",
    "    # plt.savefig(\"0to5_pr_curve_CTGENS(val_pure_kao).svg\", format = \"svg\", dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(CT_ENS_thresholds)):\n",
    "    print('precision: ', CT_ENS_precision[i], ' recall: ', CT_ENS_recall[i], ' thresholds: ', CT_ENS_thresholds[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTENS_thresh_list = []\n",
    "CTENS_accuracy_score_list = []\n",
    "CTENS_precision_score_list = []\n",
    "CTENS_recall_score_list = []\n",
    "CTENS_f1_score_list = []\n",
    "CTENS_record_f2_score = []\n",
    "CTENS_specificity_score_list = []\n",
    "CTENS_npv_score_list = []\n",
    "CTENS_confusion_matrix_list = []\n",
    "CTENS_y_pred_record = []\n",
    "CTENS_tp_fn_num_count = []\n",
    "for th in CT_ENS_thresholds:\n",
    "    \n",
    "    y_pred = [0 if (x < th) else 1 for x in y_pred_append[1]]\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    npv = tn / (fn+tn)\n",
    "    CTENS_thresh_list.append(th)\n",
    "    CTENS_accuracy_score_list.append(accuracy_score(y_test, y_pred) * 100)\n",
    "    CTENS_precision_score_list.append(precision_score(y_test, y_pred) * 100)\n",
    "    CTENS_recall_score_list.append(recall_score(y_test, y_pred) * 100)\n",
    "    CTENS_f1_score_list.append(f1_score(y_test, y_pred) * 100)\n",
    "    CTENS_record_f2_score.append(fbeta_score(y_test, y_pred, beta=2) * 100)\n",
    "    CTENS_specificity_score_list.append(specificity * 100)\n",
    "    CTENS_npv_score_list.append(npv * 100)\n",
    "    CTENS_confusion_matrix_list.append([tn, fp, fn, tp])\n",
    "    CTENS_y_pred_record.append(y_pred)\n",
    "    CTENS_tp_fn_num_count.append(pos_count_great(tmp_y_pred[:, 1], tmp_y_pred2[:, 1], y_test, y_pred))\n",
    "recall_standard_list = [80, 85, 90, 95] #\n",
    "compare = []\n",
    "for recall_standard in recall_standard_list:\n",
    "    high_recall_f1score = []\n",
    "    high_recall_f2score = []\n",
    "    high_recall_accuracy = []\n",
    "    high_recall_recall = []\n",
    "    high_recall_precision = []\n",
    "    high_recall_specificity = []\n",
    "    high_recall_npv = []\n",
    "    high_recall_confusion_matrix = []\n",
    "    high_y_pred_record = []\n",
    "    high_tp_fn_num_count = []\n",
    "    for index, recall in enumerate(CTENS_recall_score_list):\n",
    "        if recall >= recall_standard:\n",
    "            high_recall_f1score.append(CTENS_f1_score_list[index])\n",
    "            high_recall_f2score.append(CTENS_record_f2_score[index])\n",
    "            high_recall_accuracy.append(CTENS_accuracy_score_list[index])\n",
    "            high_recall_precision.append(CTENS_precision_score_list[index])\n",
    "            high_recall_recall.append(CTENS_recall_score_list[index])\n",
    "            high_recall_specificity.append(CTENS_specificity_score_list[index])\n",
    "            high_recall_npv.append(CTENS_npv_score_list[index])\n",
    "            high_recall_confusion_matrix.append(CTENS_confusion_matrix_list[index])\n",
    "            high_y_pred_record.append(CTENS_y_pred_record[index])\n",
    "            high_tp_fn_num_count.append(CTENS_tp_fn_num_count[index])\n",
    "    high_recall_best_f2_score_index = np.argmax(high_recall_f2score)\n",
    "    print(\"當Recall高於\", recall_standard, \"% 時\")\n",
    "    print(\"且選取最高的F2-score時\")\n",
    "    print(\"Recall為為:\", high_recall_recall[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"Specificity為:\", high_recall_specificity[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"Precision為:\", high_recall_precision[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"NPV為:\", high_recall_npv[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"+LR:\", (high_recall_recall[high_recall_best_f2_score_index]/100)/(1-(high_recall_specificity[high_recall_best_f2_score_index]/100)))\n",
    "    print(\"-LR:\", (1-(high_recall_recall[high_recall_best_f2_score_index]/100))/(high_recall_specificity[high_recall_best_f2_score_index]/100))\n",
    "    print(\"F1 Score為:\", high_recall_f1score[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"F2 Score為:\", high_recall_f2score[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"Accuracy為:\", high_recall_accuracy[high_recall_best_f2_score_index], \"%\")\n",
    "    print(\"TN, FP, FN, TP\", high_recall_confusion_matrix[high_recall_best_f2_score_index])\n",
    "    print(\"CTGAN-DC的TP及FN的數量:\", high_tp_fn_num_count[high_recall_best_f2_score_index])\n",
    "    # print('預測值', high_y_pred_record[high_recall_best_f2_score_index])\n",
    "    print(len(high_y_pred_record[high_recall_best_f2_score_index]))\n",
    "    print(\"============================================\")\n",
    "    compare.append(high_y_pred_record[high_recall_best_f2_score_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "for i in record_y_pred_pr:\n",
    "    xg_y_pred_roc = [x[1] for x in xg_y_pred_proba]\n",
    "    GAN_xg_y_pred_roc = [x[1] for x in GAN_xg_y_pred_proba]\n",
    "    TVAE_xg_y_pred_roc = [x[1] for x in TVAE_xg_y_pred_proba]\n",
    "    y_pred_append_roc = [x for x in y_pred_append[1]]\n",
    "    x = np.arange(0, 1, 0.001)\n",
    "    y = np.arange(0, 1, 0.001)\n",
    "    fig, ax = plt.subplots()\n",
    "    xg_fpr, xg_tpr, thresholds = metrics.roc_curve(y_test, xg_y_pred_roc, pos_label=1)\n",
    "    plt.plot(xg_fpr, xg_tpr, label = \"XG (val)\")   #, color='m'\n",
    "    # RocCurveDisplay.from_predictions(y_test, xg_y_pred_roc, name=\"XG \", ax=ax)\n",
    "    GAN_xg_fpr, GAN_xg_tpr, thresholds = metrics.roc_curve(y_test, GAN_xg_y_pred_roc, pos_label=1)\n",
    "    plt.plot(GAN_xg_fpr, GAN_xg_tpr, label = \"CTGAN + XG (val)\")     #, color='b'\n",
    "    # RocCurveDisplay.from_predictions(y_test, GAN_xg_y_pred_roc, name=\"CTGAN + XG \", ax=ax)\n",
    "    TVAE_xg_fpr, TVAE_xg_tpr, thresholds = metrics.roc_curve(y_test, TVAE_xg_y_pred_roc, pos_label=1)\n",
    "    plt.plot(TVAE_xg_fpr, TVAE_xg_tpr, label = \"TVAE + XG (val)\")     #, color='b'\n",
    "    # RocCurveDisplay.from_predictions(y_test, TVAE_xg_y_pred_roc, name=\"TVAE + XG \", ax=ax)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, i, pos_label=1)\n",
    "    plt.plot(fpr, tpr, label = \"DC (val)\")        #, color='y'\n",
    "    # RocCurveDisplay.from_predictions(y_test, i, name=\"ENS \", ax=ax)\n",
    "    CT_ENS_fpr, CT_ENS_tpr, CT_ENS_thresholds = metrics.roc_curve(y_test, y_pred_append_roc, pos_label=1)\n",
    "    plt.plot(CT_ENS_fpr, CT_ENS_tpr, label = \"CTGAN-DC (val)\")        #, color='y'\n",
    "    # RocCurveDisplay.from_predictions(y_test, y_pred_append_roc, name=\"ENS+ \", ax=ax)\n",
    "    plt.plot(x, y, color='0', linestyle = \"-.\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid(True)\n",
    "    # plt.savefig(\"0to5_roc_curve_CTGENS(val_pure_kao).svg\", format = \"svg\", dpi=500)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('tsung': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1de99697bc54ecb7a8f74ffa91c128efe0185c9fdbad375531804a37acc4d489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
